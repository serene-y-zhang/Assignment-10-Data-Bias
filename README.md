# Assignment-10-Data-Bias

**Hypothesis 

Perspective might make more mistakes when analyzing texts in languages other than English, its performance may be affected due to language and cultural differences. And the model may struggle to identify certain types of toxic language, such as sarcasm or irony, which are common in online communication.

**What biases do you think might exist in the model based on intuitions or public documentation about how the model was created?

Some bias that could exist in the model:
  1. training data bias since the dataset of comments could have inherent biases due to type of source from which the data was collected, the type of content the comments were made about could influence as well. if the data was also from more of a certain group or demographic, the model ould be less accurate when evaluating comments of another group or demographic.
  2. labeling bias since the training data was labeled by humans, they would potentailyl ahve subjetive opinions on what is considered toxic language. it can influence the model's understanding of what constitiues toxic language.
  3. selection bias since the model may not be representative of all typesof communication, selefction bias can affect the model's performace when analyzing comments in other contexts.


**What were your results?

Referencing my latest model result of [0.30427247, 0.1460314, 0.10653123, 0.11429678, 0.049584184, 0.02402467, 0.01005285, 0.20195828, 0.018095128, 0.31547862, 0.010869644, 0.30439767, 0.37955463, 0.12260055, 0.08716487, 0.030506283, 0.029563503, 0.032391842, 0.112643376, 0.049584184], what you can see here is that the socres ranges from 0.01 to 0.38 with an average of 0.145. It looks like the higher the score the more toxic where the average scores do not seem to be espcially toxic.

**How does a low sample size impact your results, and the conclusions we can draw from them?

A low sample size can impact my result with lack of representativeness since the sample maybe would not represent the entire population and any conclusiongs could be biased or inaccurate or there will be increased variability giving that the results are more likely to fluctuate wtih conclusions drawn from that are less reliable. The conclusions we can draw from them could be less reliable, inaccurate, or biased so it may be necessary to use a larger sample size so that we can get a more accurate and representative view on the model's performance.

**What theories do you have about why your results are what they are?

It seems that the toxicity scores generated by the Perspective API are quite varied, ranging from as low as 0.01 to as high as 0.38. This suggests that the model is not consistently accurate in predicting the toxicity of comments. Additionally, the fact that some scores are None suggests that the model may not be able to provide a toxicity score for some comments. And potentially some bias that were listed above were present.

**What you have learned.


Through this assignment, we explored the concept of bias in natural language processing models and specifically evaluated the performance of the Perspective API released by Google Jigsaw on a sample dataset. We used Python to query the API for toxicity scores and processed the results to generate a list of scores.We also discussed some of the potential biases that could exist in the model, such as labeling bias, and the impact of a low sample size on our results and conclusions.

Overall, this assignment highlights the importance of understanding and addressing bias in machine learning models, particularly in natural language processing, where language use and cultural norms can vary widely. It also underscores the need for careful consideration and interpretation of results when working with limited datasets.
